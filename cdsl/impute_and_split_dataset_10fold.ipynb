{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from utils.tools import forward_fill_pipeline, normalize_dataframe, normalize_df_with_statistics\n",
    "\n",
    "data_dir = \"./cdsl/\"\n",
    "Path(os.path.join(data_dir, 'processed')).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.join(data_dir, 'statistics')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_records = ['PatientID', 'RecordTime', 'AdmissionTime', 'DischargeTime']\n",
    "target_features = ['Outcome', 'LOS']\n",
    "demographic_features = ['Sex', 'Age']\n",
    "labtest_features = ['MAX_BLOOD_PRESSURE', 'MIN_BLOOD_PRESSURE', 'TEMPERATURE', 'HEART_RATE', 'OXYGEN_SATURATION', 'ADW -- Coeficiente de anisocitosis', 'ADW -- SISTEMATICO DE SANGRE', 'ALB -- ALBUMINA', 'AMI -- AMILASA', 'AP -- ACTIVIDAD DE PROTROMBINA', 'APTT -- TIEMPO DE CEFALINA (APTT)', 'AU -- ACIDO URICO', 'BAS -- Bas¢filos', 'BAS -- SISTEMATICO DE SANGRE', 'BAS% -- Bas¢filos %', 'BAS% -- SISTEMATICO DE SANGRE', 'BD -- BILIRRUBINA DIRECTA', 'BE(b) -- BE(b)', 'BE(b)V -- BE (b)', 'BEecf -- BEecf', 'BEecfV -- BEecf', 'BT -- BILIRRUBINA TOTAL', 'BT -- BILIRRUBINA TOTAL                                                               ', 'CA -- CALCIO                                                                          ', 'CA++ -- Ca++ Gasometria', 'CHCM -- Conc. Hemoglobina Corpuscular Media', 'CHCM -- SISTEMATICO DE SANGRE', 'CK -- CK (CREATINQUINASA)', 'CL -- CLORO', 'CREA -- CREATININA', 'DD -- DIMERO D', 'EOS -- Eosin¢filos', 'EOS -- SISTEMATICO DE SANGRE', 'EOS% -- Eosin¢filos %', 'EOS% -- SISTEMATICO DE SANGRE', 'FA -- FOSFATASA ALCALINA', 'FER -- FERRITINA', 'FIB -- FIBRINàGENO', 'FOS -- FOSFORO', 'G-CORONAV (RT-PCR) -- Tipo de muestra: Exudado Far¡ngeo/Nasofar¡ngeo', 'GGT -- GGT (GAMMA GLUTAMIL TRANSPEPTIDASA)', 'GLU -- GLUCOSA', 'GOT -- GOT (AST)', 'GPT -- GPT (ALT)', 'HCM -- Hemoglobina Corpuscular Media', 'HCM -- SISTEMATICO DE SANGRE', 'HCO3 -- HCO3-', 'HCO3V -- HCO3-', 'HCTO -- Hematocrito', 'HCTO -- SISTEMATICO DE SANGRE', 'HEM -- Hemat¡es', 'HEM -- SISTEMATICO DE SANGRE', 'HGB -- Hemoglobina', 'HGB -- SISTEMATICO DE SANGRE', 'INR -- INR', 'K -- POTASIO', 'LAC -- LACTATO', 'LDH -- LDH', 'LEUC -- Leucocitos', 'LEUC -- SISTEMATICO DE SANGRE', 'LIN -- Linfocitos', 'LIN -- SISTEMATICO DE SANGRE', 'LIN% -- Linfocitos %', 'LIN% -- SISTEMATICO DE SANGRE', 'MG -- MAGNESIO', 'MONO -- Monocitos', 'MONO -- SISTEMATICO DE SANGRE', 'MONO% -- Monocitos %', 'MONO% -- SISTEMATICO DE SANGRE', 'NA -- SODIO', 'NEU -- Neutr¢filos', 'NEU -- SISTEMATICO DE SANGRE', 'NEU% -- Neutr¢filos %', 'NEU% -- SISTEMATICO DE SANGRE', 'PCO2 -- pCO2', 'PCO2V -- pCO2', 'PCR -- PROTEINA C REACTIVA', 'PH -- pH', 'PHV -- pH', 'PLAQ -- Recuento de plaquetas', 'PLAQ -- SISTEMATICO DE SANGRE', 'PO2 -- pO2', 'PO2V -- pO2', 'PROCAL -- PROCALCITONINA', 'PT -- PROTEINAS TOTALES', 'SO2C -- sO2c (Saturaci¢n de ox¡geno)', 'SO2CV -- sO2c (Saturaci¢n de ox¡geno)', 'TCO2 -- tCO2(B)c', 'TCO2V -- tCO2 (B)', 'TP -- TIEMPO DE PROTROMBINA', 'TROPO -- TROPONINA', 'U -- UREA', 'VCM -- SISTEMATICO DE SANGRE', 'VCM -- Volumen Corpuscular Medio', 'VPM -- SISTEMATICO DE SANGRE', 'VPM -- Volumen plaquetar medio', 'VSG -- VSG']\n",
    "require_impute_features = labtest_features\n",
    "normalize_features = ['Age'] + labtest_features + ['LOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"processed\", f\"cdsl_dataset_formatted.csv\"))\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified split dataset into `Training`, `Validation` and `Test` sets\n",
    "\n",
    "- Also include (Imputation & Normalization & Outlier Filtering) steps\n",
    "- The train, validation and test sets are saved in the `./processed/{fold_x}` folder\n",
    "- use 8:1:1 10-fold strategy (Patient-level split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "\n",
    "# Group the dataframe by patient ID\n",
    "grouped = df.groupby('PatientID')\n",
    "\n",
    "# Split the patient IDs into train/val/test sets\n",
    "patients = np.array(list(grouped.groups.keys()))\n",
    "kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_val_index, test_index) in enumerate(kf.split(patients, df.groupby('PatientID')['Outcome'].first())):\n",
    "    # Get the train/val/test patient IDs for the current fold\n",
    "    train_val_patients, test_patients = patients[train_val_index], patients[test_index]\n",
    "\n",
    "    # Split the train_val_patients into train/val sets\n",
    "    train_patients, val_patients = train_test_split(train_val_patients, test_size=1/(num_folds-1), random_state=SEED, stratify=df[df['PatientID'].isin(train_val_patients)].groupby('PatientID')['Outcome'].first())\n",
    "\n",
    "    # Create train, val, and test dataframes for the current fold\n",
    "    train_df = df[df['PatientID'].isin(train_patients)]\n",
    "    val_df = df[df['PatientID'].isin(val_patients)]\n",
    "    test_df = df[df['PatientID'].isin(test_patients)]\n",
    "    \n",
    "    assert len(train_df) + len(val_df) + len(test_df) == len(df)\n",
    "\n",
    "    # Save the train, val, and test dataframes for the current fold to csv files\n",
    "    \n",
    "    fold_dir = os.path.join(data_dir, 'processed', f'fold_{fold}')\n",
    "    Path(fold_dir).mkdir(parents=True, exist_ok=True)\n",
    "    train_df.to_csv(os.path.join(fold_dir, \"train_raw.csv\"), index=False)\n",
    "    val_df.to_csv(os.path.join(fold_dir, \"val_raw.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(fold_dir, \"test_raw.csv\"), index=False)\n",
    "\n",
    "    # Calculate the mean and std of the train set (include age, lab test features, and LOS) on the data in 5% to 95% quantile range\n",
    "\n",
    "    # Normalize data\n",
    "    train_df, val_df, test_df, default_fill, los_info, train_mean, train_std = normalize_dataframe(train_df, val_df, test_df, normalize_features)\n",
    "    \n",
    "    # Drop rows if all features are recorded NaN\n",
    "    train_df = train_df.dropna(axis=0, how='all', subset=normalize_features)\n",
    "    val_df = val_df.dropna(axis=0, how='all', subset=normalize_features)\n",
    "    test_df = test_df.dropna(axis=0, how='all', subset=normalize_features)\n",
    "\n",
    "    # Save the train, val, and test dataframes for the current fold to csv files\n",
    "    train_df.to_csv(os.path.join(fold_dir, \"train_after_zscore.csv\"), index=False)\n",
    "    val_df.to_csv(os.path.join(fold_dir, \"val_after_zscore.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(fold_dir, \"test_after_zscore.csv\"), index=False)\n",
    "\n",
    "    # Forward Imputation after grouped by PatientID\n",
    "    # Notice: if a patient has never done certain lab test, the imputed value will be the median value calculated from train set\n",
    "    train_x, train_y, train_pid = forward_fill_pipeline(train_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "    val_x, val_y, val_pid = forward_fill_pipeline(val_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "    test_x, test_y, test_pid = forward_fill_pipeline(test_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "\n",
    "    # Save the imputed dataset to pickle file\n",
    "    pd.to_pickle(train_x, os.path.join(fold_dir, \"train_x.pkl\"))\n",
    "    pd.to_pickle(train_y, os.path.join(fold_dir, \"train_y.pkl\"))\n",
    "    pd.to_pickle(train_pid, os.path.join(fold_dir, \"train_pid.pkl\"))\n",
    "    pd.to_pickle(val_x, os.path.join(fold_dir, \"val_x.pkl\"))\n",
    "    pd.to_pickle(val_y, os.path.join(fold_dir, \"val_y.pkl\"))\n",
    "    pd.to_pickle(val_pid, os.path.join(fold_dir, \"val_pid.pkl\"))\n",
    "    pd.to_pickle(test_x, os.path.join(fold_dir, \"test_x.pkl\"))\n",
    "    pd.to_pickle(test_y, os.path.join(fold_dir, \"test_y.pkl\"))\n",
    "    pd.to_pickle(test_pid, os.path.join(fold_dir, \"test_pid.pkl\"))\n",
    "    pd.to_pickle(los_info, os.path.join(fold_dir, \"los_info.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
