{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from utils.tools import forward_fill_pipeline, normalize_dataframe, normalize_df_with_statistics, calculate_missing_rate, export_missing_mask_pipeline, get_time_interval_term\n",
    "\n",
    "data_dir = \"./mimic-iv/\"\n",
    "Path(os.path.join(data_dir, 'processed')).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.join(data_dir, 'statistics')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_features_randomly(df, X, drop_columns, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Filter for the required columns\n",
    "    sub_df = df[drop_columns]\n",
    "\n",
    "    # Compute the overall missing rate for the specified columns\n",
    "    overall_missing_rate = sub_df.isnull().mean().mean()\n",
    "    print(f\"Overall Missing Rate for Specified Columns: {overall_missing_rate * 100:.2f}%\")\n",
    "\n",
    "    # Compute the missing rate for each feature in the specified columns\n",
    "    missing_rate = sub_df.isnull().mean()\n",
    "\n",
    "    # Drop additional values based on X\n",
    "    for column in drop_columns:\n",
    "        # Ensure we don't drop values from columns that are already 100% missing\n",
    "        if missing_rate[column] < 1:\n",
    "            # Find the indices of non-missing values\n",
    "            non_missing_indices = df[column].dropna().index\n",
    "            \n",
    "            # Calculate the number of additional values to drop\n",
    "            num_to_drop = int(len(non_missing_indices) * X / 100)\n",
    "            \n",
    "            # Randomly select indices to drop\n",
    "            indices_to_drop = np.random.choice(non_missing_indices, num_to_drop, replace=False)\n",
    "            \n",
    "            # Set these values to NaN\n",
    "            df.loc[indices_to_drop, column] = np.nan\n",
    "\n",
    "\n",
    "    # # Ensure no specified column is entirely empty after dropping\n",
    "    # if df[drop_columns].dropna(axis=1, how='all').shape[1] != sub_df.shape[1]:\n",
    "    #     raise ValueError(\"Some specified columns have become completely empty after dropping!\")\n",
    "\n",
    "    cur_missing = overall_missing_rate = df[drop_columns].isnull().mean().mean()\n",
    "    print(f\"Current Overall Missing Rate: {cur_missing * 100:.2f}%\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_records = ['PatientID', 'RecordTime', 'AdmissionTime', 'DischargeTime']\n",
    "target_features = ['Outcome', 'LOS', 'Readmission']\n",
    "demographic_features = ['Sex', 'Age'] # Sex and ICUType are binary features, others are continuous features\n",
    "labtest_features = ['Capillary refill rate->0.0', 'Capillary refill rate->1.0',\n",
    "        'Glascow coma scale eye opening->To Pain',\n",
    "        'Glascow coma scale eye opening->3 To speech',\n",
    "        'Glascow coma scale eye opening->1 No Response',\n",
    "        'Glascow coma scale eye opening->4 Spontaneously',\n",
    "        'Glascow coma scale eye opening->None',\n",
    "        'Glascow coma scale eye opening->To Speech',\n",
    "        'Glascow coma scale eye opening->Spontaneously',\n",
    "        'Glascow coma scale eye opening->2 To pain',\n",
    "        'Glascow coma scale motor response->1 No Response',\n",
    "        'Glascow coma scale motor response->3 Abnorm flexion',\n",
    "        'Glascow coma scale motor response->Abnormal extension',\n",
    "        'Glascow coma scale motor response->No response',\n",
    "        'Glascow coma scale motor response->4 Flex-withdraws',\n",
    "        'Glascow coma scale motor response->Localizes Pain',\n",
    "        'Glascow coma scale motor response->Flex-withdraws',\n",
    "        'Glascow coma scale motor response->Obeys Commands',\n",
    "        'Glascow coma scale motor response->Abnormal Flexion',\n",
    "        'Glascow coma scale motor response->6 Obeys Commands',\n",
    "        'Glascow coma scale motor response->5 Localizes Pain',\n",
    "        'Glascow coma scale motor response->2 Abnorm extensn',\n",
    "        'Glascow coma scale total->11', 'Glascow coma scale total->10',\n",
    "        'Glascow coma scale total->13', 'Glascow coma scale total->12',\n",
    "        'Glascow coma scale total->15', 'Glascow coma scale total->14',\n",
    "        'Glascow coma scale total->3', 'Glascow coma scale total->5',\n",
    "        'Glascow coma scale total->4', 'Glascow coma scale total->7',\n",
    "        'Glascow coma scale total->6', 'Glascow coma scale total->9',\n",
    "        'Glascow coma scale total->8',\n",
    "        'Glascow coma scale verbal response->1 No Response',\n",
    "        'Glascow coma scale verbal response->No Response',\n",
    "        'Glascow coma scale verbal response->Confused',\n",
    "        'Glascow coma scale verbal response->Inappropriate Words',\n",
    "        'Glascow coma scale verbal response->Oriented',\n",
    "        'Glascow coma scale verbal response->No Response-ETT',\n",
    "        'Glascow coma scale verbal response->5 Oriented',\n",
    "        'Glascow coma scale verbal response->Incomprehensible sounds',\n",
    "        'Glascow coma scale verbal response->1.0 ET/Trach',\n",
    "        'Glascow coma scale verbal response->4 Confused',\n",
    "        'Glascow coma scale verbal response->2 Incomp sounds',\n",
    "        'Glascow coma scale verbal response->3 Inapprop words',\n",
    "        'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glucose',\n",
    "        'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation',\n",
    "        'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight',\n",
    "        'pH']\n",
    "require_impute_features = labtest_features\n",
    "normalize_features = ['Age'] + ['Diastolic blood pressure', 'Fraction inspired oxygen', 'Glucose',\n",
    "        'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation',\n",
    "        'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight',\n",
    "        'pH'] + ['LOS']\n",
    "\n",
    "drop_columns = ['Capillary refill rate->0.0', 'Capillary refill rate->1.0',\n",
    "        'Glascow coma scale eye opening->To Pain',\n",
    "        'Glascow coma scale eye opening->3 To speech',\n",
    "        'Glascow coma scale eye opening->1 No Response',\n",
    "        'Glascow coma scale eye opening->4 Spontaneously',\n",
    "        'Glascow coma scale eye opening->None',\n",
    "        'Glascow coma scale eye opening->To Speech',\n",
    "        'Glascow coma scale eye opening->Spontaneously',\n",
    "        'Glascow coma scale eye opening->2 To pain',\n",
    "        'Glascow coma scale motor response->1 No Response',\n",
    "        'Glascow coma scale motor response->3 Abnorm flexion',\n",
    "        'Glascow coma scale motor response->Abnormal extension',\n",
    "        'Glascow coma scale motor response->No response',\n",
    "        'Glascow coma scale motor response->4 Flex-withdraws',\n",
    "        'Glascow coma scale motor response->Localizes Pain',\n",
    "        'Glascow coma scale motor response->Flex-withdraws',\n",
    "        'Glascow coma scale motor response->Obeys Commands',\n",
    "        'Glascow coma scale motor response->Abnormal Flexion',\n",
    "        'Glascow coma scale motor response->6 Obeys Commands',\n",
    "        'Glascow coma scale motor response->5 Localizes Pain',\n",
    "        'Glascow coma scale motor response->2 Abnorm extensn',\n",
    "        'Glascow coma scale total->11', 'Glascow coma scale total->10',\n",
    "        'Glascow coma scale total->13', 'Glascow coma scale total->12',\n",
    "        'Glascow coma scale total->15', 'Glascow coma scale total->14',\n",
    "        'Glascow coma scale total->3', 'Glascow coma scale total->5',\n",
    "        'Glascow coma scale total->4', 'Glascow coma scale total->7',\n",
    "        'Glascow coma scale total->6', 'Glascow coma scale total->9',\n",
    "        'Glascow coma scale total->8',\n",
    "        'Glascow coma scale verbal response->1 No Response',\n",
    "        'Glascow coma scale verbal response->No Response',\n",
    "        'Glascow coma scale verbal response->Confused',\n",
    "        'Glascow coma scale verbal response->Inappropriate Words',\n",
    "        'Glascow coma scale verbal response->Oriented',\n",
    "        'Glascow coma scale verbal response->No Response-ETT',\n",
    "        'Glascow coma scale verbal response->5 Oriented',\n",
    "        'Glascow coma scale verbal response->Incomprehensible sounds',\n",
    "        'Glascow coma scale verbal response->1.0 ET/Trach',\n",
    "        'Glascow coma scale verbal response->4 Confused',\n",
    "        'Glascow coma scale verbal response->2 Incomp sounds',\n",
    "        'Glascow coma scale verbal response->3 Inapprop words', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glucose',\n",
    "        'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation',\n",
    "        'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight',\n",
    "        'pH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"processed\", f\"format_mimic4_ehr.csv\"))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = drop_features_randomly(df, X=20, drop_columns=drop_columns, seed=SEED)\n",
    "# fold_name = 'fold_4'\n",
    "fold_name = 'fold_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a patient has multiple records, we only use the first 48 items\n",
    "# we also discard the patients with less than 48 items\n",
    "\n",
    "# Ensure dataframe is sorted by PatientID and RecordTime\n",
    "df = df.sort_values(['PatientID', 'RecordTime'])\n",
    "\n",
    "# Filter out patients with less than 48 records\n",
    "df = df.groupby('PatientID').filter(lambda x: len(x) >= 48)\n",
    "\n",
    "# Select the first 48 records for each patient\n",
    "df = df.groupby('PatientID').head(48)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified split dataset into `Training`, `Validation` and `Test` sets\n",
    "\n",
    "- Stratified dataset according to `Outcome` column\n",
    "- Baseline: 70% Training, 10% Validation, 20% Test (No Calibration)\n",
    "    - Name: train, val, test\n",
    "- Calibration Method: 65% Training, 10% Validation, 5% Calibration, 20% Test\n",
    "    - Name: traincal, val, calib, test\n",
    "\n",
    "The validation and test set part are the same for both methods. Actually, traincal + calib = train.\n",
    "\n",
    "1. test 20/100\n",
    "2. val 10/80\n",
    "3. calib 5/70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by patient ID\n",
    "grouped = df.groupby('PatientID')\n",
    "\n",
    "# Get the patient IDs and outcomes\n",
    "patients = np.array(list(grouped.groups.keys()))\n",
    "patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in patients])\n",
    "\n",
    "# Get the train_val/test patient IDs\n",
    "train_val_patients, test_patients = train_test_split(patients, test_size=20/100, random_state=SEED, stratify=patients_outcome)\n",
    "\n",
    "# Get the train/val patient IDs\n",
    "train_val_patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in train_val_patients])\n",
    "train_patients, val_patients = train_test_split(train_val_patients, test_size=10/80, random_state=SEED, stratify=train_val_patients_outcome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, val, test, [traincal, calib] dataframes for the current fold\n",
    "train_df = df[df['PatientID'].isin(train_patients)]\n",
    "val_df = df[df['PatientID'].isin(val_patients)]\n",
    "test_df = df[df['PatientID'].isin(test_patients)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(data_dir, 'processed', fold_name) # forward fill\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Save the train, val, and test dataframes for the current fold to csv files\n",
    "# train_df.to_csv(os.path.join(save_dir, \"train_raw.csv\"), index=False)\n",
    "# val_df.to_csv(os.path.join(save_dir, \"val_raw.csv\"), index=False)\n",
    "# test_df.to_csv(os.path.join(save_dir, \"test_raw.csv\"), index=False)\n",
    "# traincal_df.to_csv(os.path.join(save_dir, \"traincal_raw.csv\"), index=False)\n",
    "# calib_df.to_csv(os.path.join(save_dir, \"calib_raw.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the train_set's missing rate and save the csv to the certain dir\n",
    "feature_missing_stats = calculate_missing_rate(train_df, demographic_features + labtest_features)\n",
    "feature_missing_array = [feature_missing_stats[f]['missing_rate'] for f in demographic_features + labtest_features]\n",
    "\n",
    "gfe = np.array([1-f for f in feature_missing_array])\n",
    "pd.to_pickle(gfe, os.path.join(save_dir, \"gfe.pkl\"))\n",
    "\n",
    "# finish exporting missing mask and local missing value\n",
    "train_mask_string, train_mask_value = export_missing_mask_pipeline(train_df, feature_missing_array, demographic_features, labtest_features)\n",
    "val_mask_string, val_mask_value = export_missing_mask_pipeline(val_df, feature_missing_array, demographic_features, labtest_features)\n",
    "test_mask_string, test_mask_value = export_missing_mask_pipeline(test_df, feature_missing_array, demographic_features, labtest_features)\n",
    "\n",
    "train_td = get_time_interval_term(train_mask_string)\n",
    "val_td = get_time_interval_term(val_mask_string)\n",
    "test_td = get_time_interval_term(test_mask_string)\n",
    "\n",
    "# save them to pickle file\n",
    "# pd.to_pickle(train_mask_string, os.path.join(save_dir, \"train_mask_string.pkl\"))\n",
    "# pd.to_pickle(train_mask_value, os.path.join(save_dir, \"train_mask_value.pkl\"))\n",
    "\n",
    "# pd.to_pickle(val_mask_string, os.path.join(save_dir, \"val_mask_string.pkl\"))\n",
    "# pd.to_pickle(val_mask_value, os.path.join(save_dir, \"val_mask_value.pkl\"))\n",
    "\n",
    "# pd.to_pickle(test_mask_string, os.path.join(save_dir, \"test_mask_string.pkl\"))\n",
    "# pd.to_pickle(test_mask_value, os.path.join(save_dir, \"test_mask_value.pkl\"))\n",
    "\n",
    "pd.to_pickle(train_td, os.path.join(save_dir, \"train_td.pkl\"))\n",
    "pd.to_pickle(val_td, os.path.join(save_dir, \"val_td.pkl\"))\n",
    "pd.to_pickle(test_td, os.path.join(save_dir, \"test_td.pkl\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and std of the train set (include age, lab test features, and LOS) on the data in 5% to 95% quantile range\n",
    "train_df, val_df, test_df, default_fill, los_info, train_mean, train_std = normalize_dataframe(train_df, val_df, test_df, normalize_features)\n",
    "\n",
    "\n",
    "# Save the zscored dataframes to csv files\n",
    "# train_df.to_csv(os.path.join(save_dir, \"train_after_zscore.csv\"), index=False)\n",
    "# val_df.to_csv(os.path.join(save_dir, \"val_after_zscore.csv\"), index=False)\n",
    "# test_df.to_csv(os.path.join(save_dir, \"test_after_zscore.csv\"), index=False)\n",
    "\n",
    "# Forward Imputation after grouped by PatientID\n",
    "# Notice: if a patient has never done certain lab test, the imputed value will be the median value calculated from train set\n",
    "train_x, train_y, train_pid = forward_fill_pipeline(train_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "val_x, val_y, val_pid = forward_fill_pipeline(val_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "test_x, test_y, test_pid = forward_fill_pipeline(test_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "\n",
    "# Save the imputed dataset to pickle file\n",
    "pd.to_pickle(train_x, os.path.join(save_dir, \"train_x.pkl\"))\n",
    "pd.to_pickle(train_y, os.path.join(save_dir, \"train_y.pkl\"))\n",
    "pd.to_pickle(train_pid, os.path.join(save_dir, \"train_pid.pkl\"))\n",
    "pd.to_pickle(val_x, os.path.join(save_dir, \"val_x.pkl\"))\n",
    "pd.to_pickle(val_y, os.path.join(save_dir, \"val_y.pkl\"))\n",
    "pd.to_pickle(val_pid, os.path.join(save_dir, \"val_pid.pkl\"))\n",
    "pd.to_pickle(test_x, os.path.join(save_dir, \"test_x.pkl\"))\n",
    "pd.to_pickle(test_y, os.path.join(save_dir, \"test_y.pkl\"))\n",
    "pd.to_pickle(test_pid, os.path.join(save_dir, \"test_pid.pkl\"))\n",
    "pd.to_pickle(los_info, os.path.join(save_dir, \"los_info.pkl\")) # LOS statistics (calculated from the train set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
