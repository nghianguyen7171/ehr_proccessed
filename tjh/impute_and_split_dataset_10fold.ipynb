{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from utils.tools import forward_fill_pipeline, normalize_dataframe, normalize_df_with_statistics\n",
    "\n",
    "data_dir = \"./tjh/\"\n",
    "Path(os.path.join(data_dir, 'processed')).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.join(data_dir, 'statistics')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_records = ['PatientID', 'RecordTime', 'AdmissionTime', 'DischargeTime']\n",
    "target_features = ['Outcome', 'LOS']\n",
    "demographic_features = ['Sex', 'Age'] # Sex, Unit1, Unit2 are binary features, others are continuous features\n",
    "labtest_features = ['Hypersensitive cardiac troponinI', 'hemoglobin', 'Serum chloride', 'Prothrombin time', 'procalcitonin', 'eosinophils(%)', 'Interleukin 2 receptor', 'Alkaline phosphatase', 'albumin', 'basophil(%)', 'Interleukin 10', 'Total bilirubin', 'Platelet count', 'monocytes(%)', 'antithrombin', 'Interleukin 8', 'indirect bilirubin', 'Red blood cell distribution width ', 'neutrophils(%)', 'total protein', 'Quantification of Treponema pallidum antibodies', 'Prothrombin activity', 'HBsAg', 'mean corpuscular volume', 'hematocrit', 'White blood cell count', 'Tumor necrosis factorα', 'mean corpuscular hemoglobin concentration', 'fibrinogen', 'Interleukin 1β', 'Urea', 'lymphocyte count', 'PH value', 'Red blood cell count', 'Eosinophil count', 'Corrected calcium', 'Serum potassium', 'glucose', 'neutrophils count', 'Direct bilirubin', 'Mean platelet volume', 'ferritin', 'RBC distribution width SD', 'Thrombin time', '(%)lymphocyte', 'HCV antibody quantification', 'D-D dimer', 'Total cholesterol', 'aspartate aminotransferase', 'Uric acid', 'HCO3-', 'calcium', 'Amino-terminal brain natriuretic peptide precursor(NT-proBNP)', 'Lactate dehydrogenase', 'platelet large cell ratio ', 'Interleukin 6', 'Fibrin degradation products', 'monocytes count', 'PLT distribution width', 'globulin', 'γ-glutamyl transpeptidase', 'International standard ratio', 'basophil count(#)', 'mean corpuscular hemoglobin ', 'Activation of partial thromboplastin time', 'Hypersensitive c-reactive protein', 'HIV antibody quantification', 'serum sodium', 'thrombocytocrit', 'ESR', 'glutamic-pyruvic transaminase', 'eGFR', 'creatinine']\n",
    "require_impute_features = labtest_features # Sex normally does not need imputation\n",
    "normalize_features = ['Age'] + labtest_features + ['LOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"processed\", f\"tjh_dataset_formatted.csv\"))\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified split dataset into `Training`, `Validation` and `Test` sets\n",
    "\n",
    "- Also include (Imputation & Normalization & Outlier Filtering) steps\n",
    "- The train, validation and test sets are saved in the `./processed/{fold_x}` folder\n",
    "- use 8:1:1 10-fold strategy (Patient-level split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "\n",
    "# Group the dataframe by patient ID\n",
    "grouped = df.groupby('PatientID')\n",
    "\n",
    "# Split the patient IDs into train/val/test sets\n",
    "patients = np.array(list(grouped.groups.keys()))\n",
    "kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_val_index, test_index) in enumerate(kf.split(patients, df.groupby('PatientID')['Outcome'].first())):\n",
    "    # Get the train/val/test patient IDs for the current fold\n",
    "    train_val_patients, test_patients = patients[train_val_index], patients[test_index]\n",
    "\n",
    "    # Split the train_val_patients into train/val sets\n",
    "    train_patients, val_patients = train_test_split(train_val_patients, test_size=1/(num_folds-1), random_state=SEED, stratify=df[df['PatientID'].isin(train_val_patients)].groupby('PatientID')['Outcome'].first())\n",
    "\n",
    "    # Create train, val, and test dataframes for the current fold\n",
    "    train_df = df[df['PatientID'].isin(train_patients)]\n",
    "    val_df = df[df['PatientID'].isin(val_patients)]\n",
    "    test_df = df[df['PatientID'].isin(test_patients)]\n",
    "    \n",
    "    assert len(train_df) + len(val_df) + len(test_df) == len(df)\n",
    "\n",
    "    # Save the train, val, and test dataframes for the current fold to csv files\n",
    "    \n",
    "    fold_dir = os.path.join(data_dir, 'processed', f'fold_{fold}')\n",
    "    Path(fold_dir).mkdir(parents=True, exist_ok=True)\n",
    "    train_df.to_csv(os.path.join(fold_dir, \"train_raw.csv\"), index=False)\n",
    "    val_df.to_csv(os.path.join(fold_dir, \"val_raw.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(fold_dir, \"test_raw.csv\"), index=False)\n",
    "\n",
    "    # Calculate the mean and std of the train set (include age, lab test features, and LOS) on the data in 5% to 95% quantile range\n",
    "\n",
    "    # Normalize data\n",
    "    train_df, val_df, test_df, default_fill, los_info, train_mean, train_std = normalize_dataframe(train_df, val_df, test_df, normalize_features)\n",
    "    \n",
    "    # Drop rows if all features are recorded NaN\n",
    "    train_df = train_df.dropna(axis=0, how='all', subset=normalize_features)\n",
    "    val_df = val_df.dropna(axis=0, how='all', subset=normalize_features)\n",
    "    test_df = test_df.dropna(axis=0, how='all', subset=normalize_features)\n",
    "\n",
    "    # Save the train, val, and test dataframes for the current fold to csv files\n",
    "    train_df.to_csv(os.path.join(fold_dir, \"train_after_zscore.csv\"), index=False)\n",
    "    val_df.to_csv(os.path.join(fold_dir, \"val_after_zscore.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(fold_dir, \"test_after_zscore.csv\"), index=False)\n",
    "\n",
    "    # Forward Imputation after grouped by PatientID\n",
    "    # Notice: if a patient has never done certain lab test, the imputed value will be the median value calculated from train set\n",
    "    train_x, train_y, train_pid = forward_fill_pipeline(train_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "    val_x, val_y, val_pid = forward_fill_pipeline(val_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "    test_x, test_y, test_pid = forward_fill_pipeline(test_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "\n",
    "    # Save the imputed dataset to pickle file\n",
    "    pd.to_pickle(train_x, os.path.join(fold_dir, \"train_x.pkl\"))\n",
    "    pd.to_pickle(train_y, os.path.join(fold_dir, \"train_y.pkl\"))\n",
    "    pd.to_pickle(train_pid, os.path.join(fold_dir, \"train_pid.pkl\"))\n",
    "    pd.to_pickle(val_x, os.path.join(fold_dir, \"val_x.pkl\"))\n",
    "    pd.to_pickle(val_y, os.path.join(fold_dir, \"val_y.pkl\"))\n",
    "    pd.to_pickle(val_pid, os.path.join(fold_dir, \"val_pid.pkl\"))\n",
    "    pd.to_pickle(test_x, os.path.join(fold_dir, \"test_x.pkl\"))\n",
    "    pd.to_pickle(test_y, os.path.join(fold_dir, \"test_y.pkl\"))\n",
    "    pd.to_pickle(test_pid, os.path.join(fold_dir, \"test_pid.pkl\"))\n",
    "    pd.to_pickle(los_info, os.path.join(fold_dir, \"los_info.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
