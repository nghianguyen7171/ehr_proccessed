{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from utils.tools import forward_fill_pipeline, normalize_dataframe, normalize_df_with_statistics, calculate_missing_rate, export_missing_mask_pipeline\n",
    "\n",
    "data_dir = \"./mimic-iv/\"\n",
    "Path(os.path.join(data_dir, 'processed')).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.join(data_dir, 'statistics')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_records = ['PatientID', 'RecordTime', 'AdmissionTime', 'DischargeTime']\n",
    "target_features = ['Outcome', 'LOS', 'Readmission']\n",
    "demographic_features = ['Sex', 'Age'] # Sex and ICUType are binary features, others are continuous features\n",
    "labtest_features = ['Capillary refill rate->0.0', 'Capillary refill rate->1.0',\n",
    "        'Glascow coma scale eye opening->To Pain',\n",
    "        'Glascow coma scale eye opening->3 To speech',\n",
    "        'Glascow coma scale eye opening->1 No Response',\n",
    "        'Glascow coma scale eye opening->4 Spontaneously',\n",
    "        'Glascow coma scale eye opening->None',\n",
    "        'Glascow coma scale eye opening->To Speech',\n",
    "        'Glascow coma scale eye opening->Spontaneously',\n",
    "        'Glascow coma scale eye opening->2 To pain',\n",
    "        'Glascow coma scale motor response->1 No Response',\n",
    "        'Glascow coma scale motor response->3 Abnorm flexion',\n",
    "        'Glascow coma scale motor response->Abnormal extension',\n",
    "        'Glascow coma scale motor response->No response',\n",
    "        'Glascow coma scale motor response->4 Flex-withdraws',\n",
    "        'Glascow coma scale motor response->Localizes Pain',\n",
    "        'Glascow coma scale motor response->Flex-withdraws',\n",
    "        'Glascow coma scale motor response->Obeys Commands',\n",
    "        'Glascow coma scale motor response->Abnormal Flexion',\n",
    "        'Glascow coma scale motor response->6 Obeys Commands',\n",
    "        'Glascow coma scale motor response->5 Localizes Pain',\n",
    "        'Glascow coma scale motor response->2 Abnorm extensn',\n",
    "        'Glascow coma scale total->11', 'Glascow coma scale total->10',\n",
    "        'Glascow coma scale total->13', 'Glascow coma scale total->12',\n",
    "        'Glascow coma scale total->15', 'Glascow coma scale total->14',\n",
    "        'Glascow coma scale total->3', 'Glascow coma scale total->5',\n",
    "        'Glascow coma scale total->4', 'Glascow coma scale total->7',\n",
    "        'Glascow coma scale total->6', 'Glascow coma scale total->9',\n",
    "        'Glascow coma scale total->8',\n",
    "        'Glascow coma scale verbal response->1 No Response',\n",
    "        'Glascow coma scale verbal response->No Response',\n",
    "        'Glascow coma scale verbal response->Confused',\n",
    "        'Glascow coma scale verbal response->Inappropriate Words',\n",
    "        'Glascow coma scale verbal response->Oriented',\n",
    "        'Glascow coma scale verbal response->No Response-ETT',\n",
    "        'Glascow coma scale verbal response->5 Oriented',\n",
    "        'Glascow coma scale verbal response->Incomprehensible sounds',\n",
    "        'Glascow coma scale verbal response->1.0 ET/Trach',\n",
    "        'Glascow coma scale verbal response->4 Confused',\n",
    "        'Glascow coma scale verbal response->2 Incomp sounds',\n",
    "        'Glascow coma scale verbal response->3 Inapprop words',\n",
    "        'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glucose',\n",
    "        'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation',\n",
    "        'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight',\n",
    "        'pH']\n",
    "require_impute_features = labtest_features\n",
    "normalize_features = ['Age'] + ['Diastolic blood pressure', 'Fraction inspired oxygen', 'Glucose',\n",
    "        'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation',\n",
    "        'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight',\n",
    "        'pH'] + ['LOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"processed\", f\"format_mimic4_ehr.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a patient has multiple records, we only use the first 48 items\n",
    "# we also discard the patients with less than 48 items\n",
    "\n",
    "# Ensure dataframe is sorted by PatientID and RecordTime\n",
    "df = df.sort_values(['PatientID', 'RecordTime'])\n",
    "\n",
    "# Filter out patients with less than 48 records\n",
    "df = df.groupby('PatientID').filter(lambda x: len(x) >= 48)\n",
    "\n",
    "# Select the first 48 records for each patient\n",
    "df = df.groupby('PatientID').head(48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified split dataset into `Training`, `Validation` and `Test` sets\n",
    "\n",
    "- Stratified dataset according to `Outcome` column\n",
    "- Baseline: 70% Training, 10% Validation, 20% Test (No Calibration)\n",
    "    - Name: train, val, test\n",
    "- Calibration Method: 65% Training, 10% Validation, 5% Calibration, 20% Test\n",
    "    - Name: traincal, val, calib, test\n",
    "\n",
    "The validation and test set part are the same for both methods. Actually, traincal + calib = train.\n",
    "\n",
    "1. test 20/100\n",
    "2. val 10/80\n",
    "3. calib 5/70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by patient ID\n",
    "grouped = df.groupby('PatientID')\n",
    "\n",
    "# Get the patient IDs and outcomes\n",
    "patients = np.array(list(grouped.groups.keys()))\n",
    "patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in patients])\n",
    "\n",
    "# Get the train_val/test patient IDs\n",
    "train_val_patients, test_patients = train_test_split(patients, test_size=20/100, random_state=SEED, stratify=patients_outcome)\n",
    "\n",
    "# Get the train/val patient IDs\n",
    "train_val_patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in train_val_patients])\n",
    "train_patients, val_patients = train_test_split(train_val_patients, test_size=10/80, random_state=SEED, stratify=train_val_patients_outcome)\n",
    "\n",
    "# Get the traincal and calib patient IDs (for calibration required methods)\n",
    "train_patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in train_patients])\n",
    "traincal_patients, calib_patients = train_test_split(train_patients, test_size=5/70, random_state=SEED, stratify=train_patients_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that traincal_patients and calib_patients are disjoint\n",
    "assert len(set(traincal_patients).intersection(set(calib_patients))) == 0\n",
    "\n",
    "# assert that traincal_patients + cal patients = train_patients. Both lengths should be equal and the union should be equal to the train_patients\n",
    "assert sorted(set(traincal_patients).union(set(calib_patients))) == sorted(train_patients)\n",
    "assert len(traincal_patients) + len(calib_patients) == len(train_patients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, val, test, [traincal, calib] dataframes for the current fold\n",
    "train_df = df[df['PatientID'].isin(train_patients)]\n",
    "val_df = df[df['PatientID'].isin(val_patients)]\n",
    "test_df = df[df['PatientID'].isin(test_patients)]\n",
    "traincal_df = df[df['PatientID'].isin(traincal_patients)]\n",
    "calib_df = df[df['PatientID'].isin(calib_patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(data_dir, 'processed', 'ff') # forward fill\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Save the train, val, and test dataframes for the current fold to csv files\n",
    "# train_df.to_csv(os.path.join(save_dir, \"train_raw.csv\"), index=False)\n",
    "# val_df.to_csv(os.path.join(save_dir, \"val_raw.csv\"), index=False)\n",
    "# test_df.to_csv(os.path.join(save_dir, \"test_raw.csv\"), index=False)\n",
    "# traincal_df.to_csv(os.path.join(save_dir, \"traincal_raw.csv\"), index=False)\n",
    "# calib_df.to_csv(os.path.join(save_dir, \"calib_raw.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the train_set's missing rate and save the csv to the certain dir\n",
    "feature_missing_stats = calculate_missing_rate(train_df, demographic_features + labtest_features)\n",
    "feature_missing_array = [feature_missing_stats[f]['missing_rate'] for f in demographic_features + labtest_features]\n",
    "\n",
    "# finish exporting missing mask and local missing value\n",
    "train_mask_string, train_mask_value = export_missing_mask_pipeline(train_df, feature_missing_array, demographic_features, labtest_features)\n",
    "val_mask_string, val_mask_value = export_missing_mask_pipeline(val_df, feature_missing_array, demographic_features, labtest_features)\n",
    "test_mask_string, test_mask_value = export_missing_mask_pipeline(test_df, feature_missing_array, demographic_features, labtest_features)\n",
    "traincal_mask_string, traincal_mask_value = export_missing_mask_pipeline(traincal_df, feature_missing_array, demographic_features, labtest_features)\n",
    "calib_mask_string, calib_mask_value = export_missing_mask_pipeline(calib_df, feature_missing_array, demographic_features, labtest_features)\n",
    "\n",
    "\n",
    "# save them to pickle file\n",
    "pd.to_pickle(train_mask_string, os.path.join(save_dir, \"train_mask_string.pkl\"))\n",
    "pd.to_pickle(train_mask_value, os.path.join(save_dir, \"train_mask_value.pkl\"))\n",
    "\n",
    "pd.to_pickle(val_mask_string, os.path.join(save_dir, \"val_mask_string.pkl\"))\n",
    "pd.to_pickle(val_mask_value, os.path.join(save_dir, \"val_mask_value.pkl\"))\n",
    "\n",
    "pd.to_pickle(test_mask_string, os.path.join(save_dir, \"test_mask_string.pkl\"))\n",
    "pd.to_pickle(test_mask_value, os.path.join(save_dir, \"test_mask_value.pkl\"))\n",
    "\n",
    "pd.to_pickle(traincal_mask_string, os.path.join(save_dir, \"traincal_mask_string.pkl\"))\n",
    "pd.to_pickle(traincal_mask_value, os.path.join(save_dir, \"traincal_mask_value.pkl\"))\n",
    "\n",
    "pd.to_pickle(calib_mask_string, os.path.join(save_dir, \"calib_mask_string.pkl\"))\n",
    "pd.to_pickle(calib_mask_value, os.path.join(save_dir, \"calib_mask_value.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and std of the train set (include age, lab test features, and LOS) on the data in 5% to 95% quantile range\n",
    "train_df, val_df, test_df, default_fill, los_info, train_mean, train_std = normalize_dataframe(train_df, val_df, test_df, normalize_features)\n",
    "traincal_df =  normalize_df_with_statistics(traincal_df, normalize_features, train_mean, train_std)\n",
    "calib_df =  normalize_df_with_statistics(calib_df, normalize_features, train_mean, train_std)\n",
    "\n",
    "# # Save the zscored dataframes to csv files\n",
    "# train_df.to_csv(os.path.join(save_dir, \"train_after_zscore.csv\"), index=False)\n",
    "# val_df.to_csv(os.path.join(save_dir, \"val_after_zscore.csv\"), index=False)\n",
    "# test_df.to_csv(os.path.join(save_dir, \"test_after_zscore.csv\"), index=False)\n",
    "# traincal_df.to_csv(os.path.join(save_dir, \"traincal_after_zscore.csv\"), index=False)\n",
    "# calib_df.to_csv(os.path.join(save_dir, \"calib_after_zscore.csv\"), index=False)\n",
    "\n",
    "# Forward Imputation after grouped by PatientID\n",
    "# Notice: if a patient has never done certain lab test, the imputed value will be the median value calculated from train set\n",
    "train_x, train_y, train_pid = forward_fill_pipeline(train_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "val_x, val_y, val_pid = forward_fill_pipeline(val_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "test_x, test_y, test_pid = forward_fill_pipeline(test_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "traincal_x, traincal_y, traincal_pid = forward_fill_pipeline(traincal_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "calib_x, calib_y, calib_pid = forward_fill_pipeline(calib_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "\n",
    "# Save the imputed dataset to pickle file\n",
    "pd.to_pickle(train_x, os.path.join(save_dir, \"train_x.pkl\"))\n",
    "pd.to_pickle(train_y, os.path.join(save_dir, \"train_y.pkl\"))\n",
    "pd.to_pickle(train_pid, os.path.join(save_dir, \"train_pid.pkl\"))\n",
    "pd.to_pickle(val_x, os.path.join(save_dir, \"val_x.pkl\"))\n",
    "pd.to_pickle(val_y, os.path.join(save_dir, \"val_y.pkl\"))\n",
    "pd.to_pickle(val_pid, os.path.join(save_dir, \"val_pid.pkl\"))\n",
    "pd.to_pickle(test_x, os.path.join(save_dir, \"test_x.pkl\"))\n",
    "pd.to_pickle(test_y, os.path.join(save_dir, \"test_y.pkl\"))\n",
    "pd.to_pickle(test_pid, os.path.join(save_dir, \"test_pid.pkl\"))\n",
    "pd.to_pickle(traincal_x, os.path.join(save_dir, \"traincal_x.pkl\"))\n",
    "pd.to_pickle(traincal_y, os.path.join(save_dir, \"traincal_y.pkl\"))\n",
    "pd.to_pickle(traincal_pid, os.path.join(save_dir, \"traincal_pid.pkl\"))\n",
    "pd.to_pickle(calib_x, os.path.join(save_dir, \"calib_x.pkl\"))\n",
    "pd.to_pickle(calib_y, os.path.join(save_dir, \"calib_y.pkl\"))\n",
    "pd.to_pickle(calib_pid, os.path.join(save_dir, \"calib_pid.pkl\"))\n",
    "pd.to_pickle(los_info, os.path.join(save_dir, \"los_info.pkl\")) # LOS statistics (calculated from the train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nan(x):\n",
    "    for i in range(len(x)):\n",
    "        if np.isnan(x[i]).any():\n",
    "            return False\n",
    "    return True\n",
    "assert check_nan(train_x)\n",
    "assert check_nan(val_x)\n",
    "assert check_nan(test_x)\n",
    "assert check_nan(traincal_x)\n",
    "assert check_nan(calib_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
