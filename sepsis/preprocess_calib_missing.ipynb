{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from utils.tools import forward_fill_pipeline, normalize_dataframe, normalize_df_with_statistics, calculate_missing_rate, export_missing_mask_pipeline\n",
    "\n",
    "data_dir = \"./sepsis/\"\n",
    "Path(os.path.join(data_dir, 'processed')).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.join(data_dir, 'statistics')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "SET_TYPE = 'a' # 'a' or 'b'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Changes:\n",
    "- ICULOS is not a feature \n",
    "\"\"\"\n",
    "basic_records = ['PatientID', 'RecordTime']\n",
    "target_features = ['Outcome', 'LOS']\n",
    "demographic_features = ['Sex', 'Age', 'HospAdmTime', 'Unit1', 'Unit2'] # Sex, Unit1, Unit2 are binary features, others are continuous features\n",
    "labtest_features = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct', 'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC', 'Fibrinogen', 'Platelets']\n",
    "require_impute_features = ['Age', 'HospAdmTime', 'Unit1', 'Unit2'] + labtest_features # Sex normally does not need imputation\n",
    "normalize_features = ['Age', 'HospAdmTime'] + labtest_features + ['LOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"processed\", f\"sepsis_set{SET_TYPE}.csv\"))\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified split dataset into `Training`, `Validation` and `Test` sets\n",
    "\n",
    "- Stratified dataset according to `Outcome` column\n",
    "- Baseline: 70% Training, 10% Validation, 20% Test (No Calibration)\n",
    "    - Name: train, val, test\n",
    "- Calibration Method: 65% Training, 10% Validation, 5% Calibration, 20% Test\n",
    "    - Name: traincal, val, calib, test\n",
    "\n",
    "The validation and test set part are the same for both methods. Actually, traincal + calib = train.\n",
    "\n",
    "1. test 20/100\n",
    "2. val 10/80\n",
    "3. calib 5/70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by patient ID\n",
    "grouped = df.groupby('PatientID')\n",
    "\n",
    "# Get the patient IDs and outcomes\n",
    "patients = np.array(list(grouped.groups.keys()))\n",
    "patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in patients])\n",
    "\n",
    "# Get the train_val/test patient IDs\n",
    "train_val_patients, test_patients = train_test_split(patients, test_size=20/100, random_state=SEED, stratify=patients_outcome)\n",
    "\n",
    "# Get the train/val patient IDs\n",
    "train_val_patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in train_val_patients])\n",
    "train_patients, val_patients = train_test_split(train_val_patients, test_size=10/80, random_state=SEED, stratify=train_val_patients_outcome)\n",
    "\n",
    "# Get the traincal and calib patient IDs (for calibration required methods)\n",
    "train_patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in train_patients])\n",
    "traincal_patients, calib_patients = train_test_split(train_patients, test_size=5/70, random_state=SEED, stratify=train_patients_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that traincal_patients and calib_patients are disjoint\n",
    "assert len(set(traincal_patients).intersection(set(calib_patients))) == 0\n",
    "\n",
    "# assert that traincal_patients + cal patients = train_patients. Both lengths should be equal and the union should be equal to the train_patients\n",
    "assert sorted(set(traincal_patients).union(set(calib_patients))) == sorted(train_patients)\n",
    "assert len(traincal_patients) + len(calib_patients) == len(train_patients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, val, test, [traincal, calib] dataframes for the current fold\n",
    "train_df = df[df['PatientID'].isin(train_patients)]\n",
    "val_df = df[df['PatientID'].isin(val_patients)]\n",
    "test_df = df[df['PatientID'].isin(test_patients)]\n",
    "traincal_df = df[df['PatientID'].isin(traincal_patients)]\n",
    "calib_df = df[df['PatientID'].isin(calib_patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(data_dir, 'processed', 'ff') # forward fill\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Save the train, val, and test dataframes for the current fold to csv files\n",
    "# train_df.to_csv(os.path.join(save_dir, \"train_raw.csv\"), index=False)\n",
    "# val_df.to_csv(os.path.join(save_dir, \"val_raw.csv\"), index=False)\n",
    "# test_df.to_csv(os.path.join(save_dir, \"test_raw.csv\"), index=False)\n",
    "# traincal_df.to_csv(os.path.join(save_dir, \"traincal_raw.csv\"), index=False)\n",
    "# calib_df.to_csv(os.path.join(save_dir, \"calib_raw.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the train_set's missing rate and save the csv to the certain dir\n",
    "feature_missing_stats = calculate_missing_rate(train_df, demographic_features + labtest_features)\n",
    "feature_missing_array = [feature_missing_stats[f]['missing_rate'] for f in demographic_features + labtest_features]\n",
    "\n",
    "# finish exporting missing mask and local missing value\n",
    "train_mask_string, train_mask_value = export_missing_mask_pipeline(train_df, feature_missing_array, demographic_features, labtest_features)\n",
    "val_mask_string, val_mask_value = export_missing_mask_pipeline(val_df, feature_missing_array, demographic_features, labtest_features)\n",
    "test_mask_string, test_mask_value = export_missing_mask_pipeline(test_df, feature_missing_array, demographic_features, labtest_features)\n",
    "traincal_mask_string, traincal_mask_value = export_missing_mask_pipeline(traincal_df, feature_missing_array, demographic_features, labtest_features)\n",
    "calib_mask_string, calib_mask_value = export_missing_mask_pipeline(calib_df, feature_missing_array, demographic_features, labtest_features)\n",
    "\n",
    "\n",
    "# save them to pickle file\n",
    "pd.to_pickle(train_mask_string, os.path.join(save_dir, \"train_mask_string.pkl\"))\n",
    "pd.to_pickle(train_mask_value, os.path.join(save_dir, \"train_mask_value.pkl\"))\n",
    "\n",
    "pd.to_pickle(val_mask_string, os.path.join(save_dir, \"val_mask_string.pkl\"))\n",
    "pd.to_pickle(val_mask_value, os.path.join(save_dir, \"val_mask_value.pkl\"))\n",
    "\n",
    "pd.to_pickle(test_mask_string, os.path.join(save_dir, \"test_mask_string.pkl\"))\n",
    "pd.to_pickle(test_mask_value, os.path.join(save_dir, \"test_mask_value.pkl\"))\n",
    "\n",
    "pd.to_pickle(traincal_mask_string, os.path.join(save_dir, \"traincal_mask_string.pkl\"))\n",
    "pd.to_pickle(traincal_mask_value, os.path.join(save_dir, \"traincal_mask_value.pkl\"))\n",
    "\n",
    "pd.to_pickle(calib_mask_string, os.path.join(save_dir, \"calib_mask_string.pkl\"))\n",
    "pd.to_pickle(calib_mask_value, os.path.join(save_dir, \"calib_mask_value.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and std of the train set (include age, lab test features, and LOS) on the data in 5% to 95% quantile range\n",
    "train_df, val_df, test_df, default_fill, los_info, train_mean, train_std = normalize_dataframe(train_df, val_df, test_df, normalize_features)\n",
    "traincal_df =  normalize_df_with_statistics(traincal_df, normalize_features, train_mean, train_std)\n",
    "calib_df =  normalize_df_with_statistics(calib_df, normalize_features, train_mean, train_std)\n",
    "\n",
    "# # Save the zscored dataframes to csv files\n",
    "# train_df.to_csv(os.path.join(save_dir, \"train_after_zscore.csv\"), index=False)\n",
    "# val_df.to_csv(os.path.join(save_dir, \"val_after_zscore.csv\"), index=False)\n",
    "# test_df.to_csv(os.path.join(save_dir, \"test_after_zscore.csv\"), index=False)\n",
    "# traincal_df.to_csv(os.path.join(save_dir, \"traincal_after_zscore.csv\"), index=False)\n",
    "# calib_df.to_csv(os.path.join(save_dir, \"calib_after_zscore.csv\"), index=False)\n",
    "\n",
    "# Forward Imputation after grouped by PatientID\n",
    "# Notice: if a patient has never done certain lab test, the imputed value will be the median value calculated from train set\n",
    "train_x, train_y, train_pid = forward_fill_pipeline(train_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "val_x, val_y, val_pid = forward_fill_pipeline(val_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "test_x, test_y, test_pid = forward_fill_pipeline(test_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "traincal_x, traincal_y, traincal_pid = forward_fill_pipeline(traincal_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "calib_x, calib_y, calib_pid = forward_fill_pipeline(calib_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "\n",
    "# Save the imputed dataset to pickle file\n",
    "pd.to_pickle(train_x, os.path.join(save_dir, \"train_x.pkl\"))\n",
    "pd.to_pickle(train_y, os.path.join(save_dir, \"train_y.pkl\"))\n",
    "pd.to_pickle(train_pid, os.path.join(save_dir, \"train_pid.pkl\"))\n",
    "pd.to_pickle(val_x, os.path.join(save_dir, \"val_x.pkl\"))\n",
    "pd.to_pickle(val_y, os.path.join(save_dir, \"val_y.pkl\"))\n",
    "pd.to_pickle(val_pid, os.path.join(save_dir, \"val_pid.pkl\"))\n",
    "pd.to_pickle(test_x, os.path.join(save_dir, \"test_x.pkl\"))\n",
    "pd.to_pickle(test_y, os.path.join(save_dir, \"test_y.pkl\"))\n",
    "pd.to_pickle(test_pid, os.path.join(save_dir, \"test_pid.pkl\"))\n",
    "pd.to_pickle(traincal_x, os.path.join(save_dir, \"traincal_x.pkl\"))\n",
    "pd.to_pickle(traincal_y, os.path.join(save_dir, \"traincal_y.pkl\"))\n",
    "pd.to_pickle(traincal_pid, os.path.join(save_dir, \"traincal_pid.pkl\"))\n",
    "pd.to_pickle(calib_x, os.path.join(save_dir, \"calib_x.pkl\"))\n",
    "pd.to_pickle(calib_y, os.path.join(save_dir, \"calib_y.pkl\"))\n",
    "pd.to_pickle(calib_pid, os.path.join(save_dir, \"calib_pid.pkl\"))\n",
    "pd.to_pickle(los_info, os.path.join(save_dir, \"los_info.pkl\")) # LOS statistics (calculated from the train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nan(x):\n",
    "    for i in range(len(x)):\n",
    "        if np.isnan(x[i]).any():\n",
    "            return False\n",
    "    return True\n",
    "assert check_nan(train_x)\n",
    "assert check_nan(val_x)\n",
    "assert check_nan(test_x)\n",
    "assert check_nan(traincal_x)\n",
    "assert check_nan(calib_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
